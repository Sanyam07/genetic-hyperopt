{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load toy data and create evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "\n",
    "boston_dataset = datasets.load_boston()\n",
    "X, y = boston_dataset.data, boston_dataset.target\n",
    "\n",
    "def evaluate_model(learner, X, y, num_folds):\n",
    "    mse = 0\n",
    "    for train_ind, val_ind in KFold(n_splits=num_folds).split(X, y):\n",
    "        learner.fit(X[train_ind, :], y[train_ind])\n",
    "        mse += mean_squared_error(learner.predict(X[val_ind, :]), y[val_ind])\n",
    "\n",
    "    print(\"MSE:\", mse/num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 22.5738170763\n"
     ]
    }
   ],
   "source": [
    "learner = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "evaluate_model(learner, X, y, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an educated guess about hyperparameters and try again\n",
    "\n",
    "Well, that seems to be not well-educated:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 27.2470565399\n"
     ]
    }
   ],
   "source": [
    "learner = RandomForestRegressor(random_state=0, n_jobs=-1, n_estimators=20, max_depth=8, \n",
    "                                min_impurity_decrease=2, criterion=\"mse\")\n",
    "evaluate_model(learner, X, y, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters using genetic-hyperopt\n",
    "\n",
    "Use your initial guess about hyperparameter values as priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0\n",
      "Calculating fitness...\n",
      "Best individual: {'n_jobs': -1, 'max_depth': 7, 'n_estimators': 24, 'max_features': 'auto', 'random_state': 0, 'min_impurity_decrease': 0.01690347756058859, 'criterion': 'mse'}\n",
      "Best score: 21.5197981536\n",
      "Population mean: 24.3662687443\n",
      "Generating children...\n",
      "---\n",
      "Generation 1\n",
      "Calculating fitness...\n",
      "Best individual: {'n_jobs': -1, 'max_depth': 8, 'n_estimators': 24, 'max_features': 'auto', 'random_state': 0, 'min_impurity_decrease': 0.008451738780294295, 'criterion': 'mse'}\n",
      "Best score: 21.0891637084\n",
      "Population mean: 23.2920095669\n",
      "Generating children...\n",
      "---\n",
      "Generation 2\n",
      "Calculating fitness...\n",
      "Best individual: {'n_jobs': -1, 'max_depth': 10, 'n_estimators': 24, 'max_features': 'auto', 'random_state': 0, 'min_impurity_decrease': 0.01690347756058859, 'criterion': 'mse'}\n",
      "Best score: 20.9701834726\n",
      "Population mean: 21.8665854789\n",
      "Generating children...\n",
      "---\n",
      "Generation 3\n",
      "Calculating fitness...\n",
      "Best individual: {'n_jobs': -1, 'max_depth': 10, 'n_estimators': 24, 'max_features': 'auto', 'random_state': 0, 'min_impurity_decrease': 0.01690347756058859, 'criterion': 'mse'}\n",
      "Best score: 20.9701834726\n",
      "Population mean: 21.7717479847\n",
      "Generating children...\n",
      "---\n",
      "Generation 4\n",
      "Calculating fitness...\n",
      "Best individual: {'n_jobs': -1, 'max_depth': 10, 'n_estimators': 24, 'max_features': 'auto', 'random_state': 0, 'min_impurity_decrease': 0.01690347756058859, 'criterion': 'mse'}\n",
      "Best score: 20.9701834726\n",
      "Population mean: 21.7777233107\n",
      "Generating children...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from param import ContinuousParam, CategoricalParam, ConstantParam\n",
    "from genetic_hyperopt import GeneticHyperopt\n",
    "\n",
    "optimizer = GeneticHyperopt(RandomForestRegressor, X, y, mean_squared_error, maximize=False)\n",
    "\n",
    "n_estimators_param = ContinuousParam(\"n_estimators\", 20, 4, min_limit=5, max_limit=100, is_int=True)\n",
    "max_depth_param = ContinuousParam(\"max_depth\", 8, 2, min_limit=3, max_limit=20, is_int=True)\n",
    "min_impurity_param = ContinuousParam(\"min_impurity_decrease\", 0.02, 0.05, min_limit=0, is_int=False)\n",
    "criterion_param = CategoricalParam(\"criterion\", [\"mse\", \"friedman_mse\"], [0.6, 0.4])\n",
    "max_features_param = CategoricalParam(\"max_features\", [\"auto\", \"sqrt\", \"log2\"])\n",
    "random_state_param = ConstantParam(\"random_state\", 0)\n",
    "n_jobs_param = ConstantParam(\"n_jobs\", -1)\n",
    "\n",
    "optimizer.add_param(random_state_param).add_param(n_jobs_param)\n",
    "optimizer.add_param(max_features_param).add_param(criterion_param)\n",
    "optimizer.add_param(n_estimators_param).add_param(max_depth_param).add_param(min_impurity_param)\n",
    "\n",
    "best_params, best_score = optimizer.evolve()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
